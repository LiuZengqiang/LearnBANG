/**
 * @file main.cpp
 * @author liuzengqiang
 * @brief multiply add sample impplemented by BANG on Cambrian MLU
 * @version 0.1
 * @date 2023-06-26
 *
 * @copyright Copyright (c) 2023
 *
 */
#include "cnrt.h"
#include <bang.h>
#include <iostream>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
/**
 * @brief 在 设备端 进行加法运算 c[i] = a[i] + b[i]
 * @param c
 * @param a
 * @param b
 * @param size 线程个数
 * @return
 */
__mlu_entry__ void multiAdd(float *c, float *a, float *b, int size)
{
    if (taskId >= size)
    {
        return;
    }
    c[taskId] = a[taskId] + b[taskId];
}

int main(int, char **)
{

    int n = 1000;
    cnrtRet_t ret; // Enumeration variables describing the return values of CNRT APIs.
    cnrtDev_t dev; // 设备 句柄

    unsigned int device_cnt;

    CNRT_CHECK(cnrtInit(0)); // 初始化运行环境, 0 表示初始化实际设备, 1 表示初始化虚拟设备

    CNRT_CHECK(cnrtGetDeviceCount(&device_cnt)); // 获取设备个数 必须在 cnrtInit(0) 之后才能正确获取设备个数
    std::cout << "device count:" << device_cnt << std::endl;
    if (device_cnt <= 0)
    {
        std::cout << "There is no MLU device.\n";
        return -1;
    }

    CNRT_CHECK(cnrtGetDeviceHandle(&dev, 0)); // 获取设备 0 的句柄,存储在 dev 中
    CNRT_CHECK(cnrtSetCurrentDevice(dev)); // 设置当前线程 使用的设备句柄 (据此设置该线程使用的设备)

    cnrtQueue_t pQueue;
    CNRT_CHECK(cnrtCreateQueue(&pQueue)); // 定义一个 队列变量 pQueue

    srand((unsigned)time(0)); // 初始化 随机数种子

    /* 申请 cpu 内存并赋值*/
    float *A_CPU = reinterpret_cast<float *>(malloc(n * sizeof(float)));
    float *B_CPU = reinterpret_cast<float *>(malloc(n * sizeof(float)));

    float *C_CPU = reinterpret_cast<float *>(malloc(n * sizeof(float)));
    for (int i = 0; i < n; i++)
    {
        A_CPU[i] = rand() % 100;
        B_CPU[i] = rand() % 100;
    }

    /* CPU端 计算 C[i] = A[i] + B[i] */
    clock_t start, finish;
    start = clock();

    for (int i = 0; i < n; i++)
    {
        C_CPU[i] = A_CPU[i] + B_CPU[i];
    }
    finish = clock();
    std::cout << "CPU cost:" << (double)(finish - start) << "\n";

    /* GPU 端申请内存、将数据拷到GPU端口 */
    float *A_GPU;
    float *B_GPU;
    float *C_GPU;
    float *D_CPU;

    cnrtMalloc((void **)&A_GPU, sizeof(float) * n);
    cnrtMalloc((void **)&B_GPU, sizeof(float) * n);
    cnrtMalloc((void **)&C_GPU, sizeof(float) * n);

    D_CPU = reinterpret_cast<float *>(malloc(n * sizeof(float)));

    CNRT_CHECK(cnrtMemcpy(A_GPU, A_CPU, sizeof(float) * n, CNRT_MEM_TRANS_DIR_HOST2DEV));
    CNRT_CHECK(cnrtMemcpy(B_GPU, B_CPU, sizeof(float) * n, CNRT_MEM_TRANS_DIR_HOST2DEV));

    /* 设置 kernel type */
    cnrtFunctionType_t kernel_type;
    kernel_type = CNRT_FUNC_TYPE_BLOCK;

    cnrtDim3_t kernel_dim;
    kernel_dim.x = 1024;
    kernel_dim.y = (n + kernel_dim.x - 1) / (kernel_dim.x);
    kernel_dim.z = 1;

    start = clock();
    std::cout << "kernel dim:(" << kernel_dim.x << "," << kernel_dim.y << "," << kernel_dim.z << ")\n";

    multiAdd<<<kernel_dim, kernel_type, pQueue>>>(C_GPU, A_GPU, B_GPU, n);
    finish = clock();
    std::cout << "GPU cost:" << (double)(finish - start) << "\n";

    // 将 multiAdd 与 cnrtMemcpyAsync 都放在 pQueue 队列中，保证在计算结果完成后 再进行数据拷贝
    // (其实程序默认使用同一个队列，因此实际上在本代码中无需显式设置队列)
    cnrtMemcpyAsync(D_CPU, C_GPU, sizeof(float) * n, pQueue, CNRT_MEM_TRANS_DIR_DEV2HOST);

    CNRT_CHECK(
        cnrtSyncQueue(pQueue)); // 必须进行队列同步, 而且这个函数的名字 cnrtSyncQueue 与最新版本的 cnrtQueueSync 不同!!!

    bool pass = true;
    for (int i = 0; i < n; i++)
    {
        if (std::abs((C_CPU[i] - D_CPU[i])) >= 1e-6)
        {

            std::cout << i << ":" << C_CPU[i] << "!=" << D_CPU[i] << ";";
            pass = false;
            break;
        }
    }
    if (pass)
    {
        std::cout << "Pass.\n";
    }
    else
    {
        std::cout << "Not Pass.\n";
    }

    /* 释放CPU,GPU内存 */
    free(A_CPU);
    free(B_CPU);
    free(C_CPU);
    free(D_CPU);

    CNRT_CHECK(cnrtFree(A_GPU));
    CNRT_CHECK(cnrtFree(B_GPU));
    CNRT_CHECK(cnrtFree(C_GPU));

    cnrtDestroyQueue(pQueue); // 销毁队列
    cnrtDestroy();            // 销毁运行环境, 与 cnrtInit() 匹配
    return 0;
}
